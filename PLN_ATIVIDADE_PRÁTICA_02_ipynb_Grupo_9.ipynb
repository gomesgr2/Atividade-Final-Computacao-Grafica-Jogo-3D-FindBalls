{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "D7hJlilKM485"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomesgr2/Atividade-Final-Computacao-Grafica-Jogo-3D-FindBalls/blob/main/PLN_ATIVIDADE_PR%C3%81TICA_02_ipynb_Grupo_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 02 [Extração e Pré-processamento de Dados + Expressões Regulares]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 02** deve ser feita utilizando o **Google Colab** com uma conta\n",
        "sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/83JggUJ1mhgWviEaA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 16/10 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "Gabriel Gomes de Oliveira Costa  \n",
        "11201921471\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:`"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: Cap 9 `\n",
        "\n",
        "`Segundo capítulo: Cap 17`\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` para identificar ERROS em 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        "Os capítulos devem ser selecionados na seguinte planilha:\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**DICA:** Por favor, insira o seu nome ou da sua equipe na ordem definida na planilha. Por exemplo, se a linha correspondente ao o GRUPO 5 já foi preenchida, a próxima equipe (GRUPO 6) deverá ser informada na próxima linha da planilha.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TIPOS DE ERROS**\n",
        "---\n"
      ],
      "metadata": {
        "id": "eD_AJQhrwJQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: consulta feita no ChatGPT\n",
        ">\n",
        "\n",
        "Um `programa Python` que utilize `expressões regulares` pode ajudar a identificar vários **tipos de erros** comuns em **livros**, especialmente erros de formatação e problemas relacionados à consistência do texto. Aqui estão alguns exemplos de erros comuns que podem ser identificados usando expressões regulares:\n",
        "\n",
        "* Erros de gramática e ortografia: erros de digitação, concordância verbal e nominal, uso incorreto de pontuação e outros erros gramaticais.\n",
        "\n",
        "* Problemas de formatação: você pode usar expressões regulares para encontrar erros de formatação, como espaços em excesso, tabulações inadequadas ou alinhamentos inconsistentes.\n",
        "\n",
        "* Abreviações e acrônimos: você pode usar expressões regulares para encontrar abreviações ou acrônimos que não foram definidos ou explicados anteriormente no texto.\n",
        "\n",
        "* Citações e referências: expressões regulares podem ser úteis para localizar citações ou referências que precisam de formatação especial.\n",
        "\n",
        "* OUTROS TIPOS DE ERROS: não considerem apenas os tipos de erros citados acima.\n",
        "\n",
        "\n",
        "**IMPORTANTE:** Lembre-se de que expressões regulares podem ser poderosas, mas também complexas. Dependendo da complexidade dos erros que você deseja identificar, pode ser necessário ajustar as expressões regulares de acordo com as características específicas do seu texto. Além disso, é importante ter em mente que as expressões regulares podem não ser a melhor ferramenta para todos os tipos de erros em livros, especialmente problemas mais contextuais ou semânticos, que podem exigir abordagens de PLN mais avançadas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gz0DTI0KYmn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A equipe que **realizar mais testes** e/ou **identificar mais erros** terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30). Os testes e possíveis erros devem ser contabizados de maneira separada.\n",
        "\n",
        ">\n",
        "\n",
        "Além disso, **por se tratar de um livro**, há um teste importante que deve ser feito. Lembre-se que o teste deve ser feito utilizando expressões regulares. A equipe que realizar esse teste, mesmo que o erro não ocorra nos capítulos selecionados, terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30).\n",
        "\n",
        "> A equipe pode considerar outros capítulos do livro para tentar identificar esse tipo de erro.\n",
        "\n",
        "**Se for a mesma equipe, o peso da avaliação será reduzido em 50% (caindo de 40 para 20)**.\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE**: a diminuição no peso da AVALIAÇÃO será aplicado para todos os membros da equipe. Esse critério será aplicado apenas para uma equipe, considerando como critério de desempate a equipe que entregar primeiro a atividade no formulário.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the constants\n",
        "URL_CHAPTER_9 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte5/cap9/cap9.html'\n",
        "URL_CHAPTER_17 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte8/cap17/cap17.html'"
      ],
      "metadata": {
        "id": "RyUailD5vi9E"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#define function to scrap information about the page\n",
        "def scrap_text_information(url) :\n",
        "   response = requests.get(url);\n",
        "   soup = BeautifulSoup(response.content, 'html.parser')\n",
        "   text_elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'span'])\n",
        "   # Extract the text from each element and concatenate them into a single string\n",
        "   scraped_text = ' '.join(element.get_text() for element in text_elements)\n",
        "   return scraped_text\n"
      ],
      "metadata": {
        "id": "PcTpq5ga8KaF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chapther_9 = scrap_text_information(URL_CHAPTER_9)\n",
        "text_chapther_17 = scrap_text_information(URL_CHAPTER_17)\n",
        "\n",
        "print(\"chapter 9 ::\", text_chapther_9)\n",
        "print(\"chapter 17 ::\", text_chapther_17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx5ZmLIjJqJY",
        "outputId": "2a99c160-0113-4bbf-fb4a-f800d1e0ba43"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chapter 9 :: 9 Semântica com Técnicas Simbólicas Sobre este livro Prefácio Como ler este livro Introdução 1  O que é PLN? 1 O que é PLN? Fala 2  Texto ou fala? 2 Texto ou fala? 3  Recursos para o processamento de fala 3 Recursos para o processamento de fala Palavras 4  Sequência de caracteres e palavras 4 Sequência de caracteres e palavras 5  Expressões multipalavras 5 Expressões multipalavras Estrutura 6  A ordem e a função das palavras em uma sentença 6 A ordem e a função das palavras em uma sentença 7  Ferramentas e recursos para o processamento sintático 7 Ferramentas e recursos para o processamento sintático Significado 8  E o significado? 8 E o significado? 9  Semântica com Técnicas Simbólicas 9 Semântica com Técnicas Simbólicas 10  Semântica Distribucional 10 Semântica Distribucional Discurso 11  Modelos discursivos 11 Modelos discursivos 12  Resolução de Correferência 12 Resolução de Correferência 13  Pragmática 13 Pragmática Dados e Modelos 14  Dataset e corpus 14 Dataset e corpus 15  Modelos de Linguagem 15 Modelos de Linguagem Aplicações 16  Recuperação de Informação 16 Recuperação de Informação 17  Extração de Informação 17 Extração de Informação 18  Tradução Automática 18 Tradução Automática 19  Correção automática de redação 19 Correção automática de redação 20  ChatGPT, MariTalk e outros agentes de conversação 20 ChatGPT, MariTalk e outros agentes de conversação Domínios 21  PLN na Saúde 21 PLN na Saúde 22  PLN no Direito 22 PLN no Direito 23  PLN em Redes Sociais 23 PLN em Redes Sociais Sociedade 24  Questões éticas em IA e PLN 24 Questões éticas em IA e PLN 25  E agora, PLN? 25 E agora, PLN? Referências Apêndice 1 (Capítulo 2) Sobre as/os autoras/es Conteúdo 9.1 9.1.1 9.1.2 9.1.3 9.2 9  Semântica com Técnicas Simbólicas 9  Semântica com Técnicas Simbólicas 9 Semântica com Técnicas Simbólicas Eloize Rossi Marques Seno  Valéria de Paiva  Vládia Pinheiro  26/09/2023 Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, tem-se analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos. A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como, detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática. Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como, reconhecimento de entidades nomeadas, identificação de expressões multi-palavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concernem, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final. 9.1 É pertinente fazer uma observação neste ponto para uma definição de base de conhecimento. Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.    Fonte: Adaptada de (Ovchinnikova, 2012, p. 9) (Ovchinnikova, 2012, p. 9) Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN - variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000). (Baader et al., 2003) (Blackburn; Bos, 2005; Eijck; Unger, 2010) (Dahl, 1994) (Shapiro, 2000) Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de assassinar) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências. (Sellars, 1953) (Brandom, 2001) Este capítulo tem como objetivo examinar, além dos frameworks semânticos tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capitulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português (OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013)), bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários, e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de textos motivador. Por fim, apresentamos as considerações finais desse capítulo. (Banarescu et al., 2013) (Copestake et al., 2005) (Fellbaum, 1998) (Baker; Fillmore; Lowe, 1998) (De Paiva; Rademaker; Melo, 2012) (Torrent; Ellsworth, 2013) (Speer; Chin; Havasi, 2016) (Anacleto et al., 2006) (Pinheiro et al., 2010) (Vrandečić; Krötzsch, 2014) (Suchanek; Kasneci; Weikum, 2007) (Navigli; Ponzetto, 2012) 9.1 Bases de Conhecimento Semântico 9.1 Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente. (Minsky, 1975) (Fillmore et al., 1976) A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de (Bates et al., 1982) e (Bobrow et al., 1977), conforme citado em (Ovchinnikova, 2012). (Bates et al., 1982) (Bobrow et al., 1977) (Ovchinnikova, 2012) Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum. (Fellbaum, 1998) (Liu; Singh, 2004) (Speer; Chin; Havasi, 2016) Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, têm-se algumas conclusões e respostas resultantes de inferências que, pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto. 9.1 Exemplo 9.1   Exemplo 9.1  Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes. Conclusões: Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnets, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português. 9.1 9.1.1 Wordnets 9.1.1 WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9. A PWN é descrita no livro (Fellbaum, 1998). (Fellbaum, 1998) Wordnets são amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio. Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verbo) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”. 9.2  A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1. (McCrae et al., 2019) Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas que dificultam a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.. No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas. Capítulo 5 Sag et al. (2002, p. 2) A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir. 9.1.1.1 Wordnets para o português 9.1.1.1 Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012). (Scarton; Aluisio, 2012) (Duran; Aluísio, 2012) Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações. (Dias-da-Silva, 2005) (Gonçalo Oliveira, 2014) (Simões; Guinovart, 2014) (De Paiva; Rademaker; Melo, 2012) (De Paiva et al., 2016; Gonçalo Oliveira, 2014) Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos. (De Paiva; Rademaker; Melo, 2012) (Melo; Weikum, 2009) Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v). 9.3  Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte. (Simões; Guinovart, 2014) (Gonçalo Oliveira, 2014) Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução. Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não? (Bond; Foster, 2013) 9.1.1.2 Análise do Exemplo Motivador usando a WordNet 9.1.1.2 Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset. 9.1 Seção 9.1 9.2 Exemplo 9.2   Exemplo 9.2  Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes. Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros: 9.2 Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram: 9.2 A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural. Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos. 9.1.2 FrameNet 9.1.2 FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições. (Baker; Fillmore; Lowe, 1998) (Fillmore et al., 1976) (Minsky, 1975) (Palmer; Gildea; Kingsbury, 2005) (Kipper; Dang; Palmer, 2000) A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18. 9.4  Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir: 9.4 (Ruppenhofer et al., 2006, pp. 67-88) (Ruppenhofer et al., 2006, pp. 111-120) Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet. (Ruppenhofer et al., 2006, pp. 104-111) Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20. FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos. Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank. 9.1.2.1 Framenets para o português 9.1.2.1 FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras. (Salomão, 2009) (Torrent et al., 2014) (Salomão, 2009) A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4). 9.5 9.4  Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos. A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão. (Barreira; Pinheiro; Furtado, 2017) O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos. (Bertoldi, 2011) (Bick, 2009) Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes. 9.1.2.2 Análise do Exemplo Motivador usando a FrameNet 9.1.2.2 Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto. Seção 9.1 9.3 Exemplo 9.3   Exemplo 9.3  Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes. Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim. 9.1.3 ConceptNet 9.1.3 ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são: (Speer; Chin; Havasi, 2016) Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos. (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) (Singh et al., 2002) A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc. Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes: (Singh et al., 2002) (Anacleto et al., 2006) (Ahn; Kedia; Blum, 2006; Kuo et al., 2009) (Bond; Foster, 2013) (Breen, 2004) (Lenat; Guha, 1989) (Auer et al., 2007) A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos: A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós. O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo. 9.6  Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges. 9.7  ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012). (Ovchinnikova, 2012) 9.1.3.1 Bases de conhecimento de senso comum para o português 9.1.3.1 Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua. O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007). (Anacleto et al., 2006) (Anacleto et al., 2007) A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português. (Pinheiro et al., 2010) (Liu; Singh, 2004) A InferenceNet-BR compõe-se de duas bases de conhecimento: \\(sp_1 = X\\) \\(Y\\) A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações: 9.8  9.1.3.2 Análise do Exemplo Motivador usando a ConceptNet 9.1.3.2 Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados). 9.1 9.4 Exemplo 9.4   Exemplo 9.4  Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes. Afirmações (edges) do termo assalto: Afirmações (edges) do termo balear (“shoot”, em inglês): Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram: 9.4 9.2 Considerações Finais 9.2 Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos. FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários. Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente. Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural. B F N A M R F FOR – â ı́ á F FOR P B â ç ã ç ã á é _ _ P B JM J P B W B P Onto.PT E W N – W N E B F N COLING https://www.w3.org/OWL/↩︎ https://www.json.org/json-pt.html↩︎ http://globalwordnet.org/↩︎ https://www.nltk.org/↩︎ https://spacy.io/universe↩︎ http://wordnet.princeton.edu/↩︎ https://conceptnet.io/↩︎ Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎ http://wordnet.princeton.edu/↩︎ https://wordnet.princeton.edu/related-projects↩︎ https://www.linguateca.pt/↩︎ https://sites.google.com/view/nilc-usp/↩︎ http://143.107.183.175:21380/portlex/index.php/en/↩︎ https://www.openwordnet-pt.org/↩︎ https://omwn.org/↩︎ O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎ https://framenet.icsi.berkeley.edu/↩︎ A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎ Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎ Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎ https://verbs.colorado.edu/semlink/. A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎ https://www2.ufjf.br/framenetbr/↩︎ https://www2.ufjf.br/framenetbr/projetos/↩︎ Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎ https://conceptnet.io/↩︎ Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎ Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎ https://github.com/commonsense/conceptnet5/wiki/Edges↩︎ A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎ Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎ As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎ Acessível em api.conceptnet.io. A documentação completa da API da Conceptnet pode ser acessada em https://github.com/commonsense/conceptnet5/wiki/API↩︎ 8  E o significado? 8 E o significado? 10  Semântica Distribucional 10 Semântica Distribucional\n",
            "chapter 17 :: 17 Extração de Informação Sobre este livro Prefácio Como ler este livro Introdução 1  O que é PLN? 1 O que é PLN? Fala 2  Texto ou fala? 2 Texto ou fala? 3  Recursos para o processamento de fala 3 Recursos para o processamento de fala Palavras 4  Sequência de caracteres e palavras 4 Sequência de caracteres e palavras 5  Expressões multipalavras 5 Expressões multipalavras Estrutura 6  A ordem e a função das palavras em uma sentença 6 A ordem e a função das palavras em uma sentença 7  Ferramentas e recursos para o processamento sintático 7 Ferramentas e recursos para o processamento sintático Significado 8  E o significado? 8 E o significado? 9  Semântica com Técnicas Simbólicas 9 Semântica com Técnicas Simbólicas 10  Semântica Distribucional 10 Semântica Distribucional Discurso 11  Modelos discursivos 11 Modelos discursivos 12  Resolução de Correferência 12 Resolução de Correferência 13  Pragmática 13 Pragmática Dados e Modelos 14  Dataset e corpus 14 Dataset e corpus 15  Modelos de Linguagem 15 Modelos de Linguagem Aplicações 16  Recuperação de Informação 16 Recuperação de Informação 17  Extração de Informação 17 Extração de Informação 18  Tradução Automática 18 Tradução Automática 19  Correção automática de redação 19 Correção automática de redação 20  ChatGPT, MariTalk e outros agentes de conversação 20 ChatGPT, MariTalk e outros agentes de conversação Domínios 21  PLN na Saúde 21 PLN na Saúde 22  PLN no Direito 22 PLN no Direito 23  PLN em Redes Sociais 23 PLN em Redes Sociais Sociedade 24  Questões éticas em IA e PLN 24 Questões éticas em IA e PLN 25  E agora, PLN? 25 E agora, PLN? Referências Apêndice 1 (Capítulo 2) Sobre as/os autoras/es Conteúdo 17.1 17.2 17.3 17.3.1 17.3.2 17.4 17.4.1 17.4.2 17.4.3 17.4.4 17.5 17.5.1 17.5.2 17.6 17.7 17  Extração de Informação 17  Extração de Informação 17 Extração de Informação Daniela Barreiro Claro  Joaquim Santos  Marlo Souza  Renata Vieira  Vládia Pinheiro  26/09/2023 17.1 Introdução 17.1 A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014). (Jurafsky; Martin, 2023; Konstantinova, 2014) Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996). (Sager, 1978; Sager; Friedman; Lyman, 1987) (DeJong, 1979) (Cowie; Lehnert, 1996) Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE). Eisenstein (2019) Jurafsky; Martin (2023) O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele. (Nadeau, 2007) (Santos; Cardoso, 2007a) A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021). Ananiadou; Mcnaught (2005) (Nasar; Jaffry; Malik, 2021) A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico. (Consortium, 2005) Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER). 17.2 Um pouco de história 17.2 Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado. Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua. Sager (1978) Sager; Friedman; Lyman (1987) DeJong (1979) Cowie (1983) DeJong (1979) Schank et al. (1973) Cowie (1983) A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996). (Grishman; Sundheim, 1996) A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters. (DARPA, 1991) (Andersen et al., 1992) A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a). (Grishman; Sundheim, 1996) Rau (1991) Wolinski; Vichot; Dillet (1995) (Santos; Cardoso, 2007a) Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995) Hearst (1992) (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995) Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998). (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998) Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação. (Brin, 1998) (Agichtein; Gravano, 2000) (Riloff; Jones; et al., 1999) (Etzioni et al., 2005; Nadeau, 2007) (Cucchiarelli; Velardi, 2001) Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades. Banko et al. (2007) Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012). (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012) Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade. 17.3 Conceituação formal: Relação e Entidade 17.3 A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros. Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas. 17.3.1 Entidade 17.3.1 Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1. Chen (1976) Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios. 17.3.2 Relação 17.3.2 Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia. No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo. Chen (1976) Guarino; Guizzardi (2015) (Fine, 2017) O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos. Guarino; Guizzardi (2015) Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades. Xavier; Lima; Souza (2015) Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área. As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta. 17.4 Extração de Informação (EI) 17.4 A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido. 17.1 Quadro 17.1 Exemplos de relações específicas na EI tradicional Quadro 17.1    Fonte: (Souza; Claro, 2014) (Souza; Claro, 2014) 17.4.1 Reconhecimento de Entidades Nomeadas 17.4.1 O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN. (Mota; Santos; Ranchhod, 2007; Nadeau, 2007) A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras. (Mota; Santos; Ranchhod, 2007) O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003). (Socher et al., 2012; Zelenko; Aone; Richardella, 2003) 17.4.2 Extração de Relações 17.4.2 A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico. (Jurafsky; Martin, 2023) 17.2 Quadro 17.2 Exemplos de relações no domínio da geografia brasileira. Quadro 17.2   Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações. 17.4.3 Extração Conjunta de Entidades e Relações 17.4.3 As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades. 17.2 De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa. (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021) (Hasegawa; Sekine; Grishman, 2004) (Socher et al., 2012) (Shaowei et al., 2022) 17.4.4 Métodos empregados para EI na literatura 17.4.4 Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas. A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI. 17.4.4.1 REN 17.4.4.1 As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês). Wolinski; Vichot; Dillet (1995) Florian et al. (2003) Liu; Yao; Lin (2019) Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes. Nadeau (2007) Riloff; Jones; et al. (1999) Etzioni et al. (2005) Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003). (Asahara; Matsumoto, 2003; Sekine, 1998) (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003) A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação. Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa. A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1. 17.1 Exemplo 17.1   Exemplo 17.1  Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG. Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas. Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15. (Lewis et al., 2020) (Liu et al., 2019) (Raffel et al., 2020) (Devlin et al., 2019) (Brown et al., 2020) Capítulo 15 Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6. (Mota; Santos, 2008; Santos; Cardoso, 2007b) (Solorio, 2007) (Ferrández et al., 2007) (Mota, 2008) (Amaral; Vieira, 2014) 17.1 Seção 17.6  (Souza; Nogueira; Lotufo, 2020) (Santos et al., 2019) (Castro; Silva; Soares, 2018) (Santos; Guimarães, 2015)  Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados. Souza; Nogueira; Lotufo (2020) (Santos et al., 2019) Castro; Silva; Soares (2018) Santos; Guimarães (2015) 17.4.4.1.1 Reconhecimento de Entidades em Domínios Específicos 17.4.4.1.1 O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz. Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017). (Habibi et al., 2017) Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa. Leitner; Rehm; Schneider (2019) (Qiu et al., 2019) Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings. (Santos; Santos; Vieira, 2020) Araujo et al. (2018) Consoli et al. (2020) 17.4.4.2 Extração de Relações 17.4.4.2 As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia. (Cowie, 1983; Sager, 1978) Hearst (1992) O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações. Hearst (1992) 17.3 Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia Quadro 17.3   \\(NP\\) \\(\\{NP\\}^\\ast NP\\) \\(NP \\{, NP\\}^\\ast\\) \\(NP\\) Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes. Riloff et al. (1993) Soderland et al. (1995) As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada. (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012): 17.2 (Socher et al., 2012) Exemplo 17.2   Exemplo 17.2  [Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\) \\(_{e1}\\) \\(_{e2}\\) Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos. \\(e1\\) \\(e2\\) Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE. Zelenko; Aone; Richardella (2003) Zhao; Grishman (2005) Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006): Culotta; McCallum; Betz (2006) 17.3 (Culotta; McCallum; Betz, 2006) Exemplo 17.3   Exemplo 17.3  George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\). \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\) Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush). Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma. (Bengio; Courville; Vincent, 2013) Socher et al. (2012) Zeng et al. (2014) Wang et al. (2016) 17.4.4.3 Extração Conjunta de Entidades e Relações 17.4.4.3 Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade. As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos. Roth; Yih (2007) Yu; Lam (2010) Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações. Li; Ji (2014) Miwa; Bansal (2016) 17.5 Extração de Informação Aberta 17.5 A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003). (Banko et al., 2007) (Meyer et al., 2003) A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar. Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês. Banko et al. (2007) (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015) Glauber; Claro (2018) A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019). Souza; Claro (2014) Pereira; Pinheiro (2015) (Barbosa; Glauber; Claro, 2016) (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018) (Glauber et al., 2018) (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019) Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009). (Bender, 2009) Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área. 17.5.1 Formalização 17.5.1 A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo. \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) \\(x_i\\) \\(X\\) \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\) \\(y = (arg_{1 }, rel, arg_{2})\\) \\(arg1\\) \\(arg2\\) \\(rel\\) \\(arg_{1}\\) \\(arg_{2}\\) 17.5.2 Abordagens 17.5.2 Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011). (Gamallo; Garcia, 2015) (Souza; Claro; Glauber, 2018) Sena; Glauber; Claro (2017) Pereira; Pinheiro (2015) (Fader; Soderland; Etzioni, 2011) O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa. (Gamallo; Garcia; Fernández-Lanza, 2012) Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011). Souza; Claro (2014) (Fader; Soderland; Etzioni, 2011) O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês). (Pereira; Pinheiro, 2015) O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA. Abreu; Vieira (2017) O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação. Sena; Glauber; Claro (2017) Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões. Souza; Claro; Glauber (2018) Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto. Gamallo; Garcia (2015) Oliveira; Claro; Souza (2022) Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa. O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês. Ro; Lee; Kang (2020) (Devlin et al., 2019) \\(arg_1, arg_2\\) \\(rel\\) Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA. Stanovsky et al. (2018) Cui; Wei; Zhou (2018) Zhang; Duh; Van Durme (2017) Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença. (Stanovsky et al., 2018) Cabral; Souza; Claro (2022) 17.6 Avaliação 17.6 A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação. Capítulo 16 A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:  \\[\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\\tag{17.1}\\]  \\[\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\\tag{17.1}\\] \\[\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\\tag{17.1}\\] A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:  \\[\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\\tag{17.2}\\]  \\[\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\\tag{17.2}\\] \\[\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\\tag{17.2}\\] Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados. Lehnert; Sundheim (1991) Lehnert; Sundheim (1991) Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:  \\[\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\\tag{17.3}\\]  \\[\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\\tag{17.3}\\] \\[\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\\tag{17.3}\\] A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio. (Grishman; Sundheim, 1996) (Sang; De Meulder, 2003) (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007) (Doddington et al., 2004) A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação. Banko et al. (2007) De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas. Glauber et al. (2018) Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012). (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012) A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como: \\(P'\\)  \\[\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\\tag{17.4}\\]  \\[\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\\tag{17.4}\\] \\[\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\\tag{17.4}\\] Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas. (Del Corro; Gemulla, 2013) (Smirnova; Cudré-Mauroux, 2018) (Stanovsky et al., 2018) (Stanovsky et al., 2018) (Léchelle; Gotti; Langlais, 2018) (Bhardwaj; Aggarwal; Mausam, 2019) Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019). (Collovini et al., 2019) Glauber et al. (2018) (Oliveira; Claro; Souza, 2022) (Gamallo; Garcia, 2015) (Collovini et al., 2019) Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022). (Malenchini et al., 2019) (Gamallo; Garcia, 2015) (Glauber; Claro; Oliveira, 2019) (Oliveira; Claro; Souza, 2022) 17.7 Considerações finais 17.7 Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI. Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN. Capítulo 15 Agradecimentos Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários. á A ï NLP EACL LSTM-CRF ACE (Automatic Content Extraction) BERT: NAACL-HLT ê ç ã ç ã á ç ã à ç ã M U C COLING We need to Discuss the Relationship: Revisiting Relationships as Modeling Constructs Proceedings of the 27th International Conference on Advanced Information Systems Engineering (CAISE 2015) Springer-Verlag Deep learning with word embeddings improves biomedical named entity recognition AI BART: ACL A BERT ç ã ç ã ç ã ı́ HAREM ç ã ı́ ç ã ç õ ó ç ã M ^ OIE BERT ê á IEEE ê ç ã ç ã á ı́ Em nossa terminologia, por um relacionamento.↩︎ https://www.adorocinema.com/↩︎ 16  Recuperação de Informação 16 Recuperação de Informação 18  Tradução Automática 18 Tradução Automática\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the rules to validate errors\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lliS2f7POX-U"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "liv9o7O1RXRM"
      },
      "execution_count": 46,
      "outputs": []
    }
  ]
}